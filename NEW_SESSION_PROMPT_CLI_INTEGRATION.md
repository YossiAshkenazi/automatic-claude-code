# üöÄ Parallel Agent Continuation Prompt - CLI Integration Project

## Context Summary
**Project**: CLI Integration Without API Keys (EPIC-001)  
**Status**: Claude CLI wrapper created, needs testing & completion. Gemini wrapper pending.  
**Key Innovation**: Using subprocess execution (like Dan Disler's agentic-drop-zones) to bypass API key requirements  
**Location**: `C:\Users\Dev\automatic-claude-code\python-sdk\`

## Current State
- ‚úÖ Claude CLI wrapper implemented (`claude_cli_wrapper.py`)
- ‚è≥ STORY-001: Testing and refinement needed
- üìã STORY-002: Gemini CLI wrapper planned
- üìã Epic and stories documented in `/docs/`

## Mission Critical Task
Complete the CLI integration project by testing Claude wrapper and implementing Gemini wrapper using parallel agents for maximum efficiency.

## Parallel Agent Deployment Strategy

Use the Task tool to launch **7-10 agents IN PARALLEL** for different aspects:

### Testing & Validation Agents (3-4 agents)
1. **test-basic-agent**: Test simple Claude CLI queries
   - Validate "What is 2+2?" works
   - Test model switching (sonnet/opus/haiku)
   - Verify no API key errors
   - Return: Test results summary (<500 tokens)

2. **test-streaming-agent**: Test real-time streaming
   - Test long responses with streaming
   - Verify line-by-line output
   - Test partial response handling
   - Return: Streaming validation results

3. **test-tools-agent**: Test Claude tool usage
   - Test Read/Write/Edit/Bash tools
   - Verify tool detection in output
   - Test error scenarios
   - Return: Tool test results

4. **test-error-agent**: Test error handling
   - Test without authentication
   - Test timeout scenarios
   - Test process killing
   - Return: Error handling report

### Implementation Agents (3-4 agents)
5. **parse-output-agent**: Study and implement Claude output parsing
   - Analyze actual Claude CLI output format
   - Improve `_parse_line()` method
   - Detect tool patterns, errors, status
   - Return: Updated parsing logic

6. **gemini-wrapper-agent**: Implement Gemini CLI wrapper
   - Copy Dan's Gemini approach from agentic-drop-zones
   - Create `gemini_cli_wrapper.py`
   - Implement --yolo and --sandbox flags
   - Return: Complete Gemini wrapper code

7. **unified-interface-agent**: Create unified multi-model interface
   - Design provider-agnostic interface
   - Support Claude/Gemini switching
   - Consistent message format
   - Return: Unified wrapper implementation

### Documentation & Examples Agents (2-3 agents)
8. **example-scripts-agent**: Create working examples
   - Simple query example
   - Streaming example
   - Multi-model comparison
   - Return: 3-4 example scripts

9. **test-suite-agent**: Create comprehensive test suite
   - Unit tests for both wrappers
   - Integration tests
   - Performance benchmarks
   - Return: Complete test file

10. **documentation-agent**: Update documentation
   - Installation guide
   - API reference
   - Troubleshooting guide
   - Return: Updated README sections

## Key Files to Reference

### Existing Implementation
- `python-sdk/claude_cli_wrapper.py` - Current Claude wrapper
- `docs/stories/story-001-test-claude-cli-wrapper.md` - Testing requirements
- `docs/stories/story-002-implement-gemini-cli-wrapper.md` - Gemini requirements
- `docs/prd/epic-001-cli-integration-without-api-keys.md` - Epic overview

### External Reference
- Dan's implementation: https://github.com/disler/agentic-drop-zones/blob/main/sfs_agentic_drop_zone.py
  - Lines 344-433: Gemini CLI implementation
  - Lines 251-343: Claude Code implementation

## Expected Deliverables

Each agent should return focused results under 1000 tokens:

1. **Testing agents**: Pass/fail status with specific issues
2. **Implementation agents**: Working code snippets
3. **Documentation agents**: Ready-to-use content

## Success Criteria
- [ ] Claude wrapper passes all tests
- [ ] Gemini wrapper implemented and working
- [ ] Unified interface supports both models
- [ ] 5+ working examples created
- [ ] Complete test suite with >90% coverage
- [ ] Documentation updated

## Execution Command Example

```python
# Deploy all agents simultaneously
agents = [
    "test-basic-agent: Test simple Claude queries",
    "test-streaming-agent: Validate streaming",
    "test-tools-agent: Test tool usage",
    "test-error-agent: Error scenarios",
    "parse-output-agent: Improve parsing",
    "gemini-wrapper-agent: Implement Gemini",
    "unified-interface-agent: Create unified API",
    "example-scripts-agent: Build examples",
    "test-suite-agent: Create tests",
    "documentation-agent: Update docs"
]

# Each agent works independently, returns concise results
# Total execution time: ~2-3 minutes with parallelization
```

## Critical Context

### Why This Matters
- **No API Keys**: Users can leverage subscriptions without API costs
- **Proven Pattern**: Based on Dan Disler's production implementation
- **Multi-Model**: Single interface for Claude, Gemini, and future models

### Technical Approach
```python
# Core pattern (from Dan's work)
process = await asyncio.create_subprocess_exec(
    cli_path,
    *args,
    stdout=asyncio.subprocess.PIPE,
    stderr=asyncio.subprocess.PIPE
)

# Stream output line by line
async for line in process.stdout:
    yield parse_line(line)
```

### Authentication Status
- Claude: Uses `claude setup-token` (subscription auth)
- Gemini: Uses Google OAuth (free tier available)
- No API keys needed for either!

## Priority Order
1. **First**: Test Claude wrapper thoroughly (agents 1-4)
2. **Second**: Fix parsing and error handling (agent 5)
3. **Third**: Implement Gemini wrapper (agent 6)
4. **Fourth**: Create unified interface (agent 7)
5. **Finally**: Examples and documentation (agents 8-10)

---

## üéØ Launch Instructions for New Session

1. Load this context
2. Use Task tool to deploy all 10 agents in parallel
3. Aggregate results from all agents
4. Run final integration test
5. Commit completed implementation

**Time Estimate**: 10-15 minutes with parallel execution vs 2+ hours sequential

**Note**: Each agent should focus on their specific task and return actionable results. The parallel execution will dramatically speed up the development process while maintaining quality.

---

*This prompt enables rapid completion of EPIC-001 through massive parallelization*