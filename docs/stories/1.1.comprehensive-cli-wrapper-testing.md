# Story 1.1: Comprehensive CLI Wrapper Testing & Validation

<!-- Powered by BMAD™ Core -->

## Status
**Draft**

## Story
**As a** developer with a Claude subscription (Pro/Max),  
**I want** comprehensive testing and validation of the CLI wrapper implementation,  
**so that** I can confidently use CLI-based AI development without API keys, knowing it's thoroughly tested for reliability, error handling, and production readiness.

## Acceptance Criteria

1. **Core Functionality Validation**: CLI wrapper executes basic prompts successfully through subprocess calls to Claude CLI
2. **Streaming Integrity Testing**: Real-time response streaming works correctly without buffering or race conditions  
3. **Tool Integration Testing**: All Claude tools (Read, Write, Edit, Bash, MCP tools) are properly captured and displayed
4. **Error Handling Robustness**: Authentication failures, timeouts, and edge cases are gracefully handled with clear messages
5. **Process Management Reliability**: Timeout enforcement, graceful termination, and process cleanup work without hanging
6. **Output Parsing Accuracy**: Different message types (stream, tool_use, error, status, thinking) are correctly identified and parsed
7. **Performance & Resource Management**: No memory leaks, proper async resource cleanup, and sub-100ms overhead vs direct CLI
8. **Cross-Platform Compatibility**: Works reliably on Windows, macOS, and Linux with consistent behavior
9. **Test Coverage Achievement**: Automated test suite achieves >90% code coverage with comprehensive scenarios
10. **Documentation Completeness**: Working examples, troubleshooting guides, and installation instructions are thorough and accurate

## Tasks / Subtasks

- [ ] **Task 1: Enhanced Output Parsing Implementation & Testing** (AC: 6)
  - [ ] Subtask 1.1: Analyze actual Claude CLI output patterns across different scenarios
  - [ ] Subtask 1.2: Implement comprehensive `_parse_line()` method with tool detection patterns (`<function_calls>`, `<invoke>`, etc.)
  - [ ] Subtask 1.3: Add detection for Claude-specific output: tool actions ("Reading file:", "Writing to file:"), status messages, thinking patterns
  - [ ] Subtask 1.4: Create unit tests for parsing edge cases: malformed JSON, partial responses, multi-line content
  - [ ] Subtask 1.5: Test parsing accuracy with real Claude CLI output samples

- [ ] **Task 2: Async Resource Management & Process Control Testing** (AC: 5, 7)
  - [ ] Subtask 2.1: Fix CancelledError handling in `_stream_output()` method 
  - [ ] Subtask 2.2: Implement proper timeout enforcement using `asyncio.timeout()`
  - [ ] Subtask 2.3: Add graceful process termination sequence (SIGTERM → wait → SIGKILL)
  - [ ] Subtask 2.4: Create comprehensive `cleanup()` method for resource management
  - [ ] Subtask 2.5: Test for async resource leaks and pipe transport errors

- [ ] **Task 3: Authentication & Error Handling Robustness** (AC: 4)
  - [ ] Subtask 3.1: Implement authentication status detection and clear error messaging
  - [ ] Subtask 3.2: Add specific error handling for "Invalid API key" scenarios with setup-token guidance
  - [ ] Subtask 3.3: Create retry logic with exponential backoff for transient failures
  - [ ] Subtask 3.4: Test error scenarios: CLI not found, network timeouts, malformed responses
  - [ ] Subtask 3.5: Add circuit breaker pattern for repeated failures

- [ ] **Task 4: Streaming Performance & Reliability Enhancement** (AC: 2, 7)
  - [ ] Subtask 4.1: Replace polling-based streaming with direct async iteration
  - [ ] Subtask 4.2: Implement proper concurrent stdout/stderr reading without race conditions  
  - [ ] Subtask 4.3: Add partial response handling and message correlation
  - [ ] Subtask 4.4: Test streaming with large responses (>10KB) and rapid message sequences
  - [ ] Subtask 4.5: Benchmark streaming performance vs direct CLI execution

- [ ] **Task 5: Comprehensive Test Suite Development** (AC: 9)
  - [ ] Subtask 5.1: Create unit tests for all wrapper methods with comprehensive mocking
  - [ ] Subtask 5.2: Build integration tests with real Claude CLI interactions (auth-dependent)
  - [ ] Subtask 5.3: Develop edge case tests: empty prompts, special characters, large inputs
  - [ ] Subtask 5.4: Create performance benchmarks and resource usage tests
  - [ ] Subtask 5.5: Implement test runner with parallel execution and detailed reporting

- [ ] **Task 6: Cross-Platform Compatibility Validation** (AC: 8)
  - [ ] Subtask 6.1: Test CLI discovery across different PATH configurations on Windows/macOS/Linux
  - [ ] Subtask 6.2: Validate subprocess execution patterns across platforms
  - [ ] Subtask 6.3: Test Unicode/emoji handling in console output across different terminals
  - [ ] Subtask 6.4: Verify proper process cleanup and signal handling per platform
  - [ ] Subtask 6.5: Create platform-specific installation and troubleshooting guides

- [ ] **Task 7: Tool Integration Testing & Validation** (AC: 3)
  - [ ] Subtask 7.1: Test all standard tools (Read, Write, Edit, Bash) with real file operations
  - [ ] Subtask 7.2: Validate MCP tool integration and server communication
  - [ ] Subtask 7.3: Test tool permission handling and security constraints
  - [ ] Subtask 7.4: Create tool usage examples with error recovery scenarios
  - [ ] Subtask 7.5: Benchmark tool execution overhead and response times

- [ ] **Task 8: Production-Ready Examples & Documentation** (AC: 10)
  - [ ] Subtask 8.1: Create 5 comprehensive examples: simple, streaming, tools, error handling, multi-model
  - [ ] Subtask 8.2: Write installation guide with authentication setup (`claude setup-token`)
  - [ ] Subtask 8.3: Develop troubleshooting guide for common issues and solutions
  - [ ] Subtask 8.4: Create API reference with all methods, options, and response formats
  - [ ] Subtask 8.5: Add migration guide from API keys to CLI-based approach

## Dev Notes

### Testing Strategy & Frameworks
Based on [Source: docs/testing-guide.md], the project uses a comprehensive testing infrastructure with three key components:

#### Epic 3 Process Management System
- **ProcessHandleTracker**: Automatic tracking and cleanup of all process handles
- **IsolatedTestRunner**: Spawns test processes with guaranteed clean termination  
- **ShutdownManager**: Coordinated graceful shutdown across all components
- **Key Requirement**: Tests must complete without hanging or requiring Ctrl+C intervention

#### Testing Framework Requirements [Source: docs/architecture/overview.md#testing-strategy]
- **Primary Framework**: Jest with TypeScript support for comprehensive integration testing
- **Coverage Target**: >90% for core SDK components
- **Test Organization**: Tests mirror source structure with separate unit and integration suites
- **Integration Requirements**: All CLI commands must produce identical results to current implementation

#### Process Management Testing [Source: docs/testing-guide.md#epic-3-process-management-testing]
- **Handle Tracking**: All subprocess handles must be tracked and cleaned up
- **Timeout Enforcement**: Processes must terminate within defined timeouts (default: 2-3 seconds)
- **Resource Leak Prevention**: Memory usage monitoring and validation of clean termination
- **Cross-Platform**: Consistent behavior across Windows, macOS, and Linux

### Architecture Integration Points [Source: docs/architecture/overview.md]

#### Core Components to Test
- **SDKClaudeExecutor**: Enhanced execution engine that replaces PTY-based execution [Source: docs/architecture/overview.md#component-architecture]
- **TaskCompletionAnalyzer**: Determines autopilot continuation based on SDK response analysis
- **SimplifiedSessionManager**: Lightweight session tracking with existing format compatibility

#### Authentication & CLI Integration [Source: docs/prd/epic-001-cli-integration-without-api-keys.md]
- **Authentication Method**: Uses `claude setup-token` for subscription-based authentication
- **CLI Execution Pattern**: `asyncio.create_subprocess_exec` for real-time streaming
- **Error Detection**: Must identify "Invalid API key" and guide users to authentication setup

#### Performance Requirements [Source: docs/prd/epic-001-cli-integration-without-api-keys.md#success-metrics]
- **Overhead Target**: <100ms overhead vs direct CLI execution
- **Success Rate**: >95% successful command execution
- **Response Time**: Real-time streaming without buffering delays
- **Resource Management**: No process hanging, clean termination guaranteed

### Technical Implementation Requirements

#### Output Parsing Enhancement [Source: docs/stories/story-001-test-claude-cli-wrapper.md]
Current `_parse_line()` method needs enhancement to detect:
- **Tool Patterns**: `<function_calls>`, `<invoke>`, `</invoke>` XML-style patterns
- **Action Phrases**: "Reading file:", "Writing to file:", "Running command:"
- **Status Messages**: "waiting", "processing", "loading" keywords
- **JSON Responses**: Both single-line and streaming JSON with proper error handling

#### Async Resource Management [Source: docs/architecture/overview.md#new-components]
Must implement proper async patterns:
- **CancelledError Handling**: Graceful handling of cancelled async operations
- **Process Cleanup**: Graceful termination sequence (SIGTERM → wait → SIGKILL)
- **Resource Tracking**: All file handles, subprocess handles, and async tasks
- **Memory Management**: No leaks in long-running autopilot sessions

#### Testing Standards

**Test File Locations**: 
- Unit tests: `python-sdk/tests/test_claude_cli_wrapper.py`
- Integration tests: `python-sdk/tests/test_integration_claude_cli.py`
- Example scripts: `python-sdk/examples/` directory

**Testing Frameworks**:
- **Primary**: pytest with asyncio support for Python components
- **Mocking**: unittest.mock for subprocess and CLI interactions
- **Coverage**: pytest-cov for coverage reporting and validation

**Specific Testing Requirements**:
- **Authentication Testing**: Mock `claude setup-token` scenarios and error states
- **Subprocess Testing**: Mock `asyncio.create_subprocess_exec` for unit tests
- **Streaming Testing**: Test concurrent stdout/stderr reading patterns
- **Resource Cleanup**: Validate proper cleanup using Epic 3 process management components

### Project Structure Alignment [Source: docs/architecture/overview.md#new-file-organization]

**Core Files to Test**:
- `python-sdk/claude_cli_wrapper.py` - Primary wrapper implementation
- `python-sdk/gemini_cli_wrapper.py` - Gemini wrapper for multi-model support
- `python-sdk/unified_cli_wrapper.py` - Unified interface

**Integration Points**:
- CLI discovery and PATH resolution across platforms
- Subprocess execution with proper environment handling
- Session logging compatibility with existing log analysis tools
- Hook script integration for monitoring system compatibility

## Testing

### Core Testing Requirements [Source: docs/testing-guide.md]

**Process Management Validation**:
- Epic 3 Process Management System must be fully operational (8/8 components)
- All tests must complete without hanging or requiring manual Ctrl+C
- Clean termination guaranteed within 2-3 seconds maximum
- Zero "nested session detected" warnings during test execution

**Framework Integration**:
- **Health Check Validation**: `node health-check.js` must show 100% success rate
- **Manual Test Integration**: `npx tsx src/__tests__/manual/testSDKAutopilot.ts` must complete successfully
- **Resource Leak Prevention**: Handle tracking and cleanup validation required

**Coverage and Quality Standards**:
- **Unit Test Coverage**: >90% for core wrapper functionality
- **Integration Test Coverage**: All CLI interaction patterns tested
- **Performance Testing**: Benchmark against direct CLI execution
- **Cross-Platform Testing**: Windows, macOS, and Linux compatibility verified

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-02 | 1.0 | Initial story creation with comprehensive testing focus | Bob (Scrum Master) |